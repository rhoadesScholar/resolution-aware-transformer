ablations:
  architecture_depth: true
  attention_type: true
  feature_dims: true
  multi_resolution: true
  positional_encoding: true
checkpoints:
  mode: max
  monitor: val_dice_score
  save_dir: /nrs/cellmap/rhoadesj/resolution-aware-transformer/experiments/checkpoints
  save_last: true
  save_top_k: 3
cluster:
  distributed_backend: nccl
  find_unused_parameters: true
  num_gpus: 8
data:
  data_dir: /tmp/rat_data/rat_data_146607625
  image_size: 256
  num_workers: 16
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 2
description: Comprehensive ablation study for Resolution Aware Transformer components
evaluation:
  batch_size: 16
experiment_name: rat_ablation_study
logging:
  backend: tensorboard
  log_dir: /nrs/cellmap/rhoadesj/resolution-aware-transformer/experiments/results/tensorboard_logs
  log_freq: 50
  save_predictions: true
model:
  base:
    attention_type: dense
    feature_dims: 128
    input_features: 3
    learnable_rose: true
    mlp_dropout: 0.1
    mlp_ratio: 4
    multi_scale: false
    num_blocks: 4
    num_heads: 8
    spatial_dims: 2
quick: false
seed: 42
training:
  batch_size: 2
  effective_batch_size: 16
  eval_freq: 2
  gradient_accumulation_steps: 4
  gradient_clip: 1.0
  mixed_precision: true
  num_epochs: 10
  optimizer:
    lr: 1e-4
    name: adamw
    weight_decay: 0.01
  save_freq: 5
  scheduler:
    min_lr: 1e-6
    name: cosine
