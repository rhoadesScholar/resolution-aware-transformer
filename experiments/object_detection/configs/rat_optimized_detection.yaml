name: "RAT_Optimized_Object_Detection"
description: "Memory-optimized Resolution-Aware Transformer for COCO object detection matching baseline model size (~19M params)"

model:
  name: "rat_detection"
  
  # Optimized parameters for ~19M parameters
  feature_dims: 256    # Standard feature dimensions
  num_blocks: 4        # Standard number of blocks
  num_heads: 16        # Standard attention heads
  
  # Sparse attention for memory efficiency - sparse early, dense later
  attention_type: ["sparse", "sparse", "dense", "dense"]
  
  # Detection-specific parameters
  num_classes: 91  # COCO has 91 classes including background
  num_queries: 100  # Number of object queries for DETR-style detection
  
  # Multi-scale configuration optimized for memory efficiency
  multi_scale: true
  scales: [512, 640]  # Reduced scales for better memory usage
  
  # Loss weights
  bbox_loss_coef: 5.0
  giou_loss_coef: 2.0
  class_loss_coef: 1.0
  focal_alpha: 0.25
  focal_gamma: 2.0

  # Positional encoding
  positional_encoding: "rose"
  learnable_rose: true
  
  # MLP optimization
  mlp_ratio: 4      # Standard MLP ratio
  mlp_dropout: 0.1

data:
  data_dir: "/nrs/cellmap/rhoadesj/resolution-aware-transformer/experiments/data/coco"
  train_split: "train2017"
  val_split: "val2017"
  image_size: 512  # Standard size for object detection
  batch_size: 8    # Per-GPU batch size - optimized for H100 80GB with DeepSpeed Stage 2
  num_workers: 4
  pin_memory: true

training:
  num_epochs: 50
  
  optimizer:
    name: "adamw"
    lr: 1e-4      # Standard learning rate for this model size
    weight_decay: 0.01
    betas: [0.9, 0.999]
  
  scheduler:
    name: "cosine"
    min_lr: 1e-6
  
  # Enable mixed precision for efficiency (handled by DeepSpeed)
  mixed_precision: true
  gradient_clip: 1.0

eval:
  eval_interval: 5
  save_interval: 10

logging:
  experiment_name: "rat_optimized_detection_deepspeed"
  save_dir: "./checkpoints"
  log_interval: 50

# DeepSpeed Stage 2 configuration (not Stage 3)
deepspeed:
  # Use Stage 2 for good performance/memory balance
  zero_stage: 2
  
  # No CPU offloading for Stage 2 (better performance)
  cpu_offload: false
  
  # Moderate activation checkpointing to save memory
  activation_checkpointing: true
  
  # Optimized bucket sizes for Stage 2
  stage2_reduce_bucket_size: 5e8
  stage2_allgather_bucket_size: 5e8